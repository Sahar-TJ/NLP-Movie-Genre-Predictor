# Search Engine Design

The search engine is constructed to find TV shows based on user queries using an indexed database that was saved when we ran the index.py file. The primary components of the search process encompass preprocessing user queries, transforming them into TF-IDF vectors, and then calculating cosine similarities against the indexed data. To prepare the data, both the indexed database content and user queries are tokenized, lowercased, and lemmatized using NLTK. Lemmatization ensures that words in different forms, but with similar meanings, are treated as one. Once the query is preprocessed, it is vectorized using TF-IDF representation to capture the term frequency and inverse document frequency. The cosine similarity metric is then employed to measure the similarity between the query and indexed shows, ensuring that the results are ranked by relevance. The top matches, in this case, the top 3 most similar TV shows, are returned to the user.

The choice of using TF-IDF for indexing and querying ensures that the search engine accurately captures the importance of words in the database and the query, differentiating between common and rare terms. Additionally, cosine similarity aids in identifying the angle between two vectors, giving a measure of how related two pieces of content are. Using lemmatization during preprocessing standardizes the data, allowing for more accurate matches irrespective of the morphological form of the words. This combination of preprocessing, vector representation, and similarity calculation ensures efficient and relevant search results, catering to user needs. Moreover I had even tried using GloVe in the indexing, I couldn't get the right results. They weren't as accurate as this. 